{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bae6ad07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\aadip\\anaconda\\lib\\site-packages (3.6.1)\n",
      "Requirement already satisfied: click in c:\\users\\aadip\\anaconda\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\aadip\\anaconda\\lib\\site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex in c:\\users\\aadip\\anaconda\\lib\\site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\aadip\\anaconda\\lib\\site-packages (from nltk) (4.59.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: pyodbc 4.0.0-unsupported has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pyodbc or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a802a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74f04fe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to dictionary database...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\aadip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering meaningful 5-letter words...\n",
      "Done! Created a list of 9972 words.\n",
      "Saved to: solutions.txt\n"
     ]
    }
   ],
   "source": [
    "def generate_meaningful_five_letter_words():\n",
    "    # Download the wordnet corpus (the \"dictionary\" with meanings)\n",
    "    print(\"Connecting to dictionary database...\")\n",
    "    nltk.download('words')\n",
    "    \n",
    "    # Use a set to store unique words\n",
    "    all_words = words.words()\n",
    "    meaningful_words = set()\n",
    "    \n",
    "    # wordnet.all_lemma_names() provides words that actually have definitions\n",
    "    print(\"Filtering meaningful 5-letter words...\")\n",
    "    for word in all_words:\n",
    "        # Filter for 5 letters and ensure it's alphabetic only\n",
    "        if len(word) == 5 and word.isalpha():\n",
    "            meaningful_words.add(word.upper())\n",
    "    \n",
    "    # Sort them alphabetically\n",
    "    sorted_words = sorted(list(meaningful_words))\n",
    "    \n",
    "    # Save to file\n",
    "    with open('solutions.txt', 'w') as f:\n",
    "        for word in sorted_words:\n",
    "            f.write(word + '\\n')\n",
    "            \n",
    "    print(f\"Done! Created a list of {len(sorted_words)} words.\")\n",
    "    print(\"Saved to: solutions.txt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_meaningful_five_letter_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "536f8dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dictionary and frequency data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aadip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\aadip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering...\n",
      "Refining complete! Reduced list to 2162 common words.\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import wordnet, brown\n",
    "\n",
    "def filter_common_words(input_file, output_file):\n",
    "    # 1. Download necessary data\n",
    "    print(\"Loading dictionary and frequency data...\")\n",
    "    nltk.download('wordnet')\n",
    "    nltk.download('brown')\n",
    "    \n",
    "    # 2. Get a set of common words from the Brown corpus\n",
    "    # This identifies words actually used in literature/news\n",
    "    common_usage = set(w.upper() for w in brown.words())\n",
    "    \n",
    "    # 3. Read your current 10,000 words\n",
    "    with open(input_file, 'r') as f:\n",
    "        my_words = [line.strip().upper() for line in f]\n",
    "    \n",
    "    final_list = []\n",
    "    \n",
    "    print(\"Filtering...\")\n",
    "    for word in my_words:\n",
    "        # Check A: Does it have a definition in WordNet?\n",
    "        has_definition = len(wordnet.synsets(word)) > 0\n",
    "        \n",
    "        # Check B: Is it used in the common usage corpus?\n",
    "        is_common = word in common_usage\n",
    "        \n",
    "        # We keep it if it has a definition AND is commonly used\n",
    "        if has_definition and is_common:\n",
    "            final_list.append(word)\n",
    "            \n",
    "    # 4. Save the high-quality list\n",
    "    with open(output_file, 'w') as f:\n",
    "        for word in sorted(final_list):\n",
    "            f.write(word + '\\n')\n",
    "            \n",
    "    print(f\"Refining complete! Reduced list to {len(final_list)} common words.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filter_common_words('words.txt', 'solutions.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f079c2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading English word lists...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\aadip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\aadip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating words against dictionary definitions...\n",
      "Success! Created a list of 4288 words.\n",
      "Saved to: solutions.txt\n"
     ]
    }
   ],
   "source": [
    "def generate_validated_five_letter_words():\n",
    "    # 1. Download necessary data\n",
    "    print(\"Loading English word lists...\")\n",
    "    nltk.download('words')\n",
    "    nltk.download('wordnet')\n",
    "    \n",
    "    # 2. Start with the comprehensive word list\n",
    "    all_english_words = words.words()\n",
    "    \n",
    "    # 3. Filter for length and meaningfulness\n",
    "    print(\"Validating words against dictionary definitions...\")\n",
    "    valid_words = set()\n",
    "    \n",
    "    for word in all_english_words:\n",
    "        # Check A: Length is exactly 5 and it's all letters\n",
    "        if len(word) == 5 and word.isalpha():\n",
    "            upper_word = word.upper()\n",
    "            \n",
    "            # Check B: Does WordNet recognize it as having a definition?\n",
    "            # wordnet.synsets() handles plurals like 'BALLS' by linking them to 'BALL'\n",
    "            if wordnet.synsets(upper_word):\n",
    "                valid_words.add(upper_word)\n",
    "    \n",
    "    # 4. Sort and Save\n",
    "    sorted_list = sorted(list(valid_words))\n",
    "    \n",
    "    with open('solutions.txt', 'w') as f:\n",
    "        for word in sorted_list:\n",
    "            f.write(word + '\\n')\n",
    "            \n",
    "    print(f\"Success! Created a list of {len(sorted_list)} words.\")\n",
    "    print(\"Saved to: solutions.txt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    generate_validated_five_letter_words()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c1342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
